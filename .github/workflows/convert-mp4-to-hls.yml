# ============================================================================
#  GitHub Actions Workflow: Transcode MP4 âžœ singleâ€‘file CMAFâ€‘DASH and upload
#  to CloudflareÂ R2 (S3â€‘compatible) in just a handful of PUT operations.
# ----------------------------------------------------------------------------
#  â€¢ Trigger manually from the Actions tab (workflow_dispatch) and provide:
#       â€¢ src           â€“ path to the .mp4 in the repo (e.g. lectures/week1.mp4)
#       â€¢ output_prefix â€“ key prefix in your R2 bucket (e.g. lectures/week1)
#  â€¢ Secrets you must create in the repo:
#       â€¢ R2_ACCESS_KEY_ID       â€“ Cloudflare R2 access key
#       â€¢ R2_SECRET_ACCESS_KEY   â€“ Cloudflare R2 secret key
#       â€¢ R2_BUCKET              â€“ Bucket name (no s3://, just the name)
#       â€¢ R2_ENDPOINT            â€“ Endpoint URL (e.g. https://<accountid>.r2.cloudflarestorage.com)
#       â€¢ R2_PUBLIC_DOMAIN       â€“ (optional) CDN domain to build playback URL
# ============================================================================

name: "Transcode MP4 to singleâ€‘file DASH and upload to CloudflareÂ R2"

on:
  workflow_dispatch:
    inputs:
      src:
        description: "Relative path to the .mp4 file (e.g. lectures/week1.mp4)"
        required: true
        type: string
      output_prefix:
        description: "R2 key prefix (e.g. lectures/week1)"
        required: true
        type: string

env:
  R2_BUCKET: ${{ secrets.R2_BUCKET }}
  R2_ENDPOINT: ${{ secrets.R2_ENDPOINT }}
  AWS_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}

jobs:
  build-and-upload:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install FFmpeg & AWS CLI
        run: |
          sudo apt-get update -y
          sudo apt-get install -y ffmpeg awscli

      - name: Create output directory
        run: mkdir -p dash_out

      - name: Transcode to singleâ€‘file CMAFâ€‘DASH
        shell: bash
        run: |
          INPUT="${{ github.event.inputs.src }}"
          BASENAME=$(basename "${INPUT%.*}")          # e.g. week1

          # Optional: scale/bitâ€‘rate for additional renditions. Add more blocks
          # with different -vf scale and -b:v, then combine using MP4Box if needed.

          ffmpeg -i "$INPUT" \
            -c:v libx264 -crf 22 -preset fast \
            -c:a aac -b:a 128k \
            -seg_duration 6 \
            -use_template 1 -use_timeline 1 -single_file 1 \
            -init_seg_name init.mp4 \
            -media_seg_name media.m4s \
            -adaptation_sets "id=0,streams=v id=1,streams=a" \
            -f dash "dash_out/${BASENAME}.mpd"

      - name: Upload DASH package to CloudflareÂ R2
        shell: bash
        run: |
          OUTPUT_PREFIX="${{ github.event.inputs.output_prefix }}"
          aws s3 cp dash_out "s3://${R2_BUCKET}/${OUTPUT_PREFIX}/" --recursive --endpoint-url "${R2_ENDPOINT}"

      - name: Display playback URL
        if: ${{ secrets.R2_PUBLIC_DOMAIN != '' }}
        shell: bash
        run: |
          BASENAME=$(basename "${{ github.event.inputs.src }}" .mp4)
          echo "\nðŸŽ‰  Your DASH stream is ready:"
          echo "https://${{ secrets.R2_PUBLIC_DOMAIN }}/${{ github.event.inputs.output_prefix }}/${BASENAME}.mpd"
